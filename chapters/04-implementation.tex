\chapter{本提案手法の実装}\label{cha:Implementation}
本提案手法は、領域座標取得部、文字情報取得部、ラベル付与部の3つの処理部で構成する。
本提案手法の構成を、図(refつける。全体図を修正しておくこと)に示す。
以降、本章では3つの処理部について説明する。


\section{領域座標取得部}\label{sec:area_coords_obtainment_part}
領域座標取得部は、帳票画像内記入欄を検知し、取得した座標を領域座標として出力する。
矩形の帳票画像記入欄については、各頂点のxy座標を、下線部の帳票画像記入欄については、両端点のxy座標を領域座標として取得する。
領域座標取得部の出力結果は、ラベル付与部(\ref{subsec:label_link_processing}節で後述)で用いる。


\subsection{矩形領域座標取得処理}\label{subsec:rect_coords_obtainment_processing}
矩形領域座標取得処理は、矩形の記入欄を検知し、各頂点のxy座標を矩形領域座標として取得し、出力する処理である。
矩形の取得にあたり、処理画像は白または黒でなければならないため、帳票画像に画像処理を施す必要がある。
以下に必要な画像処理の順を示す。

\begin{enumerate}
    \item OpenCVのcvtColor関数を用いた、帳票画像のグレースケール化\\
        グレースケール化によってDeblurGANv2で生成したブレ除去後の画像を、グレースケール画像に変換する。
    \item DeblurGANv2の適用によるブレ除去後のグレースケール化帳票画像の生成\\
        DeblurGANv2を適用することにより、スマートフォンで帳票画像を撮影する際に発生する画像内のブレを除去し、矩形の検出精度を高める。
    \item OpenCVのGaussianBlur関数を用いた、ガウシアンフィルタによるノイズ除去\\
        本提案手法では、カーネルの縦幅と横幅を共に3、標準偏差を0とする。
    \item OpenCVのthreshold関数を用いた、大津の二値化による二値画像への変換\\
        本提案手法では、閾値処理を大津の二値化としたTHRESH\_TOZERO\_INVによる二値化手法とする。
        白黒を反転して二値化することにより、複数の矩形が隣接する場合に、それらを外接する最小の外接矩形を不要に検出してしまうことを防ぐ。
\end{enumerate}

画像処理後、OpenCVのfindContours関数による輪郭検出を用いて矩形領域座標を取得する。
なお、以下のいずれかに該当する矩形については、出力の対象外とする。

\begin{itemize}
    \item 面積が3000ピクセル以下である場合
    \item ある辺の長さが10ピクセル以下である場合
\end{itemize}


\subsection{下線部領域座標取得処理}\label{subsec:underline_coords_obtainment_processing}
下線部領域座標取得処理は、下線部の記入欄を検知し、両端点のxy座標を下線部領域座標として取得し、出力する処理である。
下線部の取得にあたり、処理画像は白または黒でなければならないため、帳票画像に画像処理を施す必要がある。以下に必要な画像処理の順を示す。
なお、本処理における画像処理の一部は\ref{subsec:rect_coords_obtainment_processing}節と同様の画像処理を施す。

\begin{enumerate}
    \item OpenCVのcvtColor関数を用いた、帳票画像のグレースケール化\\
        \ref{subsec:rect_coords_obtainment_processing}節と同様の処理
    \item DeblurGANv2の適用によるブレ除去後のグレースケール化帳票画像の生成\\
        \ref{subsec:rect_coords_obtainment_processing}節と同様の処理
    \item OpenCVのthreshold関数を用いた、大津の二値化による二値画像への変換\\
        本提案手法では、閾値処理を大津の二値化としたTHRESH\_BINARYによる二値化手法とする。
    \item Canny 法によるエッジ検出\\
        本提案手法では、閾値処理における上限と下限の閾値を、以下のように決定する。
        \begin{enumerate}
            \item 構成画素の画素値の中央値を取得する。
            \item 中央値の定数倍(本研究では定数を0.33とする)を、取得した中央値から加減算する。
            \item 加算した値を上限の閾値、減算した値を下限の閾値として設定する。
        \end{enumerate}
\end{enumerate}

画像処理後、OpenCVのHoughLinesP関数によるハフ変換を用いて直線を両端点のxy座標を取得する。
なお、以下のいずれかに該当する直線については、出力の対象外とする。

\begin{itemize}
    \item 直線の長さが10ピクセル未満である場合
    \item 水平を基準として傾きが3ピクセル以上である場合
    \item 矩形領域の辺の一部である場合
\end{itemize}

エッジ検出を施すことにより、直線の検出精度が向上するが、直線の上下に2本の直線を検出してしまう場合がある。
これに対しては、検出した直線の中点を全て計算し、ある直線における中点のy座標について、上下10ピクセル以内に別の直線の中点が存在する場合は、二直線の両端点間xy座標をそれぞれ平均して一本の直線に統一することによって不具合を解消する。




\section{文字情報取得部}\label{sec:OCR_part}
文字情報取得部では、光学文字認識ソフトTesseract-OCRを用いて、文字と、文字を囲うバウンディングボックスを文字位置として取得する。
文字情報取得部の出力結果は、ラベル付与部(\ref{subsec:label_link_processing}節で後述)で用いる。

\subsection{文字認識処理}\label{subsec:char_recognition_processing}
文字認識処理は、認識した文字を取得文字として取得する処理である。
文字の取得にあたり、文字の認識精度を高めるため、以下の順で帳票画像に画像処理を施す。

\begin{enumerate}
    \item DeblurGANv2の適用によるブレ除去後のグレースケール化帳票画像の生成\\
        \ref{subsec:rect_coords_obtainment_processing}節と同様の処理
    \item OpenCVのcvtColor関数を用いた、帳票画像のグレースケール化\\
        \ref{subsec:rect_coords_obtainment_processing}節と同様の処理
    \item OpenCVのthreshold関数を用いた、大津の二値化による二値画像への変換\\
\end{enumerate}

画像処理後、Tesseract-OCRによる文字認識を行う。

\subsection{文字位置取得処理}\label{subsec:char_position_obtainment_processing}
文字位置取得処理は、認識した文字を囲うバウンディングボックスの頂点座標を文字位置として取得する処理である。
\ref{subsec:char_recognition_processing}節の文字認識処理と同時に、文字位置を取得する。

文字位置取得後、バウンディングボックスの左上の頂点座標について、y座標の値が小さい順に\ref{subsec:char_recognition_processing}節で取得した文字と組とし、番号を割り振る。y座標が同じ場合は、さらにx座標が小さい順にソートする。
しかし、複数の文字列が同じ行に存在する、すなわちy座標が同じ文字列が複数存在する際に、左右の順番がバラバラと場合がある。
これは、Tesseract-OCRが文字を認識する順番を、y座標をピクセル単位でソートするため、人間の目視による認識とソートの順番に違いが生じるためである。
\ref{subsec:label_link_processing}節のラベル付与部で文字位置を扱う際に、この認識とソート結果の齟齬が生じてしまう場合、ラベルの更新順が変化してしまうため、意図しないラベルを領域座標に割り付ける不具合が発生する可能性がある。
この不具合の発生を防ぐため、ソートで比較する値は、y座標を10分の1にした値(小数点以下切り捨て)を用いてソートを行う。


\subsection{除外判定処理}\label{subsec:exclusion_judgement_processing}
除外判定処理は、Fugashiによる形態素解析を行い、属性判定処理(\ref{subsec:att_prediction_processing}で後述)に不要である取得文字について、出力から除外する処理である。
形態素の品詞を解析し、検出した文字列の構成形態素数のうち、特定の品詞である形態素数の割合が半分以上である場合は、属性判定において意味を成さない取得文字であるとし、該当の取得文字と文字位置を出力の対象外とする。
文字を認識する際に、紙面と背景の境界や、矩形や直線を文字として誤認識する場合がある。
不要な文字の属性推測を防ぐことにより、処理時間を短縮することが可能である。
除外対象である形態素の品詞を、UniDic品詞体系(左からカンマ区切りで、大分類、中分類、小分類、細分類)をもとに以下に示す。
なお、除外対象とする品詞は経験から決定している。

\begin{itemize}
    \item 補助記号,一般,*,*
    \item 感動詞,フィラー,*,*
\end{itemize}


\section{ラベル付与部}\label{sec:label_link_part}
ラベル付与部では、\ref{subsec:char_recognition_processing}で取得した文字の属性を日付(date)、文字列(string)、数値(number)の3つから適当なものを推測し、取得した領域にラベルとして付与する。
付与するラベルの種類は、領域近傍の取得文字から推測する属性に依存する。
領域座標と、領域座標に対応するラベルを組としたJSON形式のファイルを出力とする。


\subsection{属性推測処理}\label{subsec:att_prediction_processing}
属性推測処理では、取得文字に対して、日付(date)、文字列(string)、数値(number)の3つの属性のいずれに該当するかを推測する。属性が判別不可である取得文字は、文字列として属性を推測する。
属性の推測には、大規模言語モデルYouriを用いる。YouriはLlama2を日本語の学習データで継続事前学習を行った大規模言語モデルである。
大規模言語モデルの出力は属性の候補以外である可能性があるため、Youriの出力から3つの属性のうちいずれかに補正を行う。
日本語の推論に特化した言語モデルを利用することによって、\ref{subsec:char_recognition_processing}節で取得した日本語の文字に属性をより正確に判別することが可能となる。
属性を推測する流れを以下に示す。
以下の処理は、\ref{subsec:char_position_obtainment_processing}節でソートを行った順番で、文字を認識した回数だけ繰り返す。\\

\begin{enumerate}
    \item \ref{subsec:exclusion_judgement_processing}節の出力である除外判定後の取得文字を受け取る。
    \item 以下のプロンプトを入力として属性を推測する。\\
        書類の項目として、（取得文字）は、という欄に記入する内容がどのデータ型に該当するかを、日付、文字列、数値の中から最も適切なものを選べ。
    \item 出力結果の文字列に取得文字と同じ文字を含む場合は、出力結果から取得文字のみを削除する。\\
        出力の最大トークン数を50トークンに制限することにより、属性判定ではない出力(単語の説明や類語の出力など)を防ぐ。
        属性判定ではない出力は、経験から出力に取得文字と同じ文字を含む傾向にある。
        後述する属性の補正を行うにあたり、取得文字に含む文字から補正を行い、意図しない属性に補正することを防ぐ。
    \item 以下の条件分岐により、属性を補正する。
        \begin{itemize}
            \item 出力に「日」を含む場合は、日付(date)を属性として判定する。
            \item 出力に「数」を含む場合は、数値(number)を属性として判定する。
            \item 判定不可または「日」、「数」を含まない場合は、文字列(string)として判定する。
        \end{itemize}
\end{enumerate}



\subsection{ラベル割付処理}\label{subsec:label_link_processing}
ラベル割付処理では、\ref{sec:area_coords_obtainment_part}節で取得した領域座標に対して、近傍に存在する文字の属性を割り付ける。
\ref{subsec:att_prediction_processing}節で推測した属性と、\ref{subsec:char_position_obtainment_processing}節で取得した文字位置をもとに、取得文字近傍の領域座標に対して、推測した属性を割り付ける。
領域座標にラベルを割り付ける流れを以下に示す。

\begin{enumerate}
    \item 文字位置であるバウンディングボックスの中心点のxy座標を計算する。
    \item 取得した領域座標のうち、右下の頂点座標のxy座標が計算した中心点のxy座標よりも共に大きい場合は、文字位置に対応する取得文字の属性を割り付ける。
    \item 既にラベルを割り付けた領域座標は、ラベルを更新する。
\end{enumerate}

以上の繰り返し処理後、\ref{sec:area_coords_obtainment_part}節で取得した領域座標と、領域座標に対応するラベルの組をJSON形式で出力する。
