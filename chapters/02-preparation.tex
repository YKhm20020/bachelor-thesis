\chapter{研究の準備}\label{cha:Preparation}
本章では、本研究に必要な前提知識について説明する。

\section{入力対象の画像}\label{sec:input_images}
試作したツールの入力対象である画像については、以下の条件を全て満たすものとする。
なお、帳票は帳簿と伝票の総称であり、電子文書はWordやテキストファイルなど、デジタル情報として作成した文書を指し、電子化文書は紙媒体の書類をスキャンした、PDFファイルや画像の形式で保存した文書を指す\cite{電子文書と電子化文書}。
試作したツールにおいて、電子化文書はスマートフォンのカメラで撮影した帳票画像を想定する。

\begin{itemize}
	\item 帳票の電子文書または電子化文書の画像である。
	\item 帳票の背景が白色である。
	\item 日本語かつ横書きの帳票である。
	\item 文字が手書きではない。
	\item 入力欄が矩形または下線で示されている。
\end{itemize}

なお、入力対象とする画像の座標系は、画像左上隅画素を原点(0,0)とし、右方向をX軸の正の向き、下方向をY軸の正の向きと定義する。

\section{バリデーションチェック}\label{sec:validation_check}
バリデーションチェックとは、入力フィールドに記入した内容やデータベースに記入する内容の妥当性を確認することである\cite{バリデーションチェック}。
例えば、メールアドレスの入力フィールドに対して、アルファベットと数字のみを入力の対象とする、「@」を必須入力とするなどの、仕様に沿わない書式の入力を防ぐことができる。

\section{Numpy}\label{sec:Numpy}
Numpyは、高速な数値計算ができる、Python\cite{Python}の数値計算ライブラリである\cite{Numpy}。
行列やベクトルなどの、多次元配列を計算する関数が実装されており、主に機械学習や画像処理の分野で用いる。

本研究では、Numpyに用意されている以下の関数を用いる。

\paragraph{randint関数}
randint関数は、擬似乱数を生成する乱数生成関数をまとめたrandomモジュールのうち、任意の範囲の整数値を出力する関数である\cite{randint関数}。
第一引数として、出力する乱数の下限の値を指定する。
また、第二引数として、出力する乱数の上限の値を指定する。
さらに、第三引数として、出力する乱数の形状を指定する。
第三引数については省略可能であり、省略した場合は1つの整数値を出力する。

本研究では、領域強調画像出力処理(\ref{subsec:area_highlighted_image_output_processing}節で後述)で矩形領域を帳票画像に描画する際に、ランダムなRGBカラーを決定する際に用いる。

\paragraph{histogram関数}
histogram関数は、引数に渡す配列に対して、ヒストグラムの配列を出力する関数である\cite{histogram関数}。
第一引数として、ヒストグラムを作成するにあたり、参照する配列を指定する。
また、第二引数として、ヒストグラムのビンの数を指定する。
さらに、第三引数として、ビンの範囲を指定する。
第二引数、および第三引数は省略可能であり、省略した場合は、初期値として10、第一引数で渡した配列の最小値から最大値をそれぞれ代入する。

本研究では、帳票画像のRGB値のヒストグラムを作成し、R、G、Bの各色空間の最頻値を取得するために用いる。

\section{OpenCV}\label{sec:OpenCV}
OpenCV(Open Source Computer Vision Library) は、コンピュータビジョン向けのオープンソースライブラリである\cite{OpenCV}。
本研究では、OpenCVに用意されている以下の関数を用いる。

\paragraph{imread関数}
imread関数は、画像ファイルを読み込み、多次元配列に変換する関数である\cite{imread関数}。
返り値である多次元配列は、1番目の次元から順に、画像の高さ、画像の幅、RGB値の情報を持つ。
カラー画像であれば、3番目の次元は3次元配列であり、グレースケール画像であれば、2次元配列である。

\paragraph{imwrite関数}
imwrite関数は、多次元配列を画像ファイルに変換し、保存する関数である。

\paragraph{cvtColor関数}
cvtColor関数は、画像の色空間を変換する関数である。
本研究では、読み込んだ画像をグレースケール化するために用いる。
この処理は、カラー画像をグレースケール化することにより、画像処理に必要な計算量を減らすために行う。

\paragraph{getStructuringElement関数}
getStructuringElement関数は、カーネルを作成する関数である\cite{getStructuringElement関数}。
カーネルは、ガウシアンフィルタ(GaussianBlur関数で後述)や膨張処理(dilate関数で後述)など、注目画素の周囲の画素値を参照する画像処理において、周囲の画素値を行列として、その行列を参照する計算に付ける重みである。
例えば、3行3列の矩形カーネルは、注目画素とその周囲8画素の画素値の、計9画素の画素値を用いて計算を行う。
第一引数として、カーネルの形状を矩形、楕円、十字から決定する変数を指定する。
また、第二引数では、カーネルの大きさを指定する。
なお、本研究では、第一引数を、カーネルの形状を矩形に決定する、MORPH\_RECTを用いる。
本研究では、矩形領域座標取得用画像処理(\ref{subsec:image_processing_for_rect_coords_obtainment}節で後述)に必要な画像処理の一部として用いる。

\paragraph{GaussianBlur関数}
GaussianBlur関数は、ガウシアンフィルタを適用することにより、画像内の白色ノイズを除去する関数である。
ガウシアンフィルタは、注目画素との距離に応じて重みを変えるガウシアンカーネルを用いた、画像の平滑化(ぼかし)によって白色ノイズを除去するフィルタである。
第一引数として、画像の多次元配列を指定する。
また、第二関数として、カーネルを指定する。
さらに、第三引数、第四引数として、それぞれ縦と横の標準偏差を指定する。
標準偏差が大きいほど、小さなノイズを除去できるが、ぼかしが強くなる。
なお、第四引数は省略可能であり、標準偏差を$0$とすることによって、カーネルの大きさから自動的に標準偏差を計算する\cite{ガウシアンフィルタ}。
本研究では、矩形領域座標取得用画像処理(\ref{subsec:image_processing_for_rect_coords_obtainment}節で後述)に必要な画像処理の一部として用いる。

\paragraph{threshold関数}
threshold関数は、画像を二値化する関数である。
第一引数として、グレースケール画像を指定する。
また、第二引数では、二値化する際の閾値を指定し、第三引数では、二値化後の画素値の最大値を指定する。
さらに、第四引数では、二値化における閾値処理手法を指定する。
本研究では、大津の二値化を用いて、閾値を決定する。
大津の二値化(判別分析法)は、画素値のヒストグラムにおけるクラス間分散とクラス内分散の比である分離度が最大となる閾値を求める手法である\cite{大津の二値化}。
大津の二値化を用いることによって、画像に適する閾値を自動で決定することができる。
大津の二値化による閾値処理を設定する場合は、第四引数に、変数THRESH\_OTSUを加算演算子+で接続する。
なお、一般に8ビット画像について、画素値は0に近づくほど黒色を、255に近づくほど白色を表すとされている\cite{画素値}。

本研究で用いる閾値処理手法を指定する変数を、以下に示す。

\begin{itemize}
	\item THRESH\_BINARY\\
		大津の二値化を用いる場合は、大津の二値化によって決定した閾値を基準に、ある注目画素の画素値が閾値よりも小さい場合は画素値を第三引数で設定する値に変換し、閾値よりも大きい場合は画素数を0に変換して二値化する。
		本研究では、下線部領域座標取得用画像処理(\ref{subsec:image_processing_for_underline_coords_obtainment}節で後述)と、文字情報取得用画像処理(\ref{subsec:image_processing_for_char_recognition}節で後述)で設定する。
	\item THRESH\_TOZERO\_INV\\
		大津の二値化を用いる場合は、大津の二値化によって決定した閾値を基準に、ある注目画素の画素値が閾値よりも小さい場合は画素値を変換せず、閾値よりも大きい場合は画素値を第三引数で設定する値に変換して二値化する。
		本研究では、矩形領域座標取得用画像処理(\ref{subsec:image_processing_for_rect_coords_obtainment}節で後述)で設定する。
\end{itemize}

\paragraph{dilate関数}
dilate関数は、画像に膨張処理を行う関数である。
膨張処理は、ある注目画素について、一定周囲の画素集合内に白色に二値化した画素がある場合は、注目画素の画素値をカーネル内画素の最大画素値に変更する処理である\cite{膨張処理}。
第一引数として、二値画像を指定する。
また、第二引数では、カーネルを指定する。
さらに、第三引数では、膨張処理を行う回数を指定する。
本研究では、矩形領域座標取得用画像処理(\ref{subsec:image_processing_for_rect_coords_obtainment}節で後述)で行う画像処理の一部として用いる。

\paragraph{Canny関数}
Canny関数は、Canny法によって黒色と白色の境界である、エッジを検出する関数である。
エッジ検出は、画像内の輝度差を検出することにより、物体や領域の境界を識別する処理である\cite{エッジ検出}。
Canny法は、ガウシアンフィルタでノイズを除去し、ソーベルフィルタでエッジの勾配と方向を検出し、エッジを細線化した後に勾配と方向からエッジ検出を行う手法である。
Canny法におけるエッジ検出の閾値処理については、最小閾値と最大閾値を決め、画素値の微分値が最大閾値よりも大きい画素と、それらに隣接しており、かつ最小閾値よりも大きく最大閾値よりも小さい画素のみをエッジとみなすヒステリシス閾値処理を用いる\cite{Canny法}。
第一引数として、二値画像を指定する。
また、第二引数では、最小閾値を指定する。
さらに、第三引数では、最大引数を指定する。
本研究では、下線部領域座標取得用画像処理(\ref{subsec:image_processing_for_underline_coords_obtainment}節で後述)で下線部領域座標の取得に必要な画像処理の一部として用いる。

\paragraph{findContours関数}
findContours関数は、黒い背景の画像内にある白い物体の輪郭を検出する関数である。
第一引数として、二値化処理後の画像である二値画像を指定する。
また、第二引数では、検出する輪郭と、それらを保存する構造を決定する変数を指定する。
本研究では、全ての輪郭を検出し、それらを外側から順に入れ子とした階層構造とするRECT\_TREEを指定する。
さらに、第三引数では、輪郭となる頂点の近似法を決定する変数を指定する。
本研究では、輪郭を表現するにあたり、冗長な点の情報を削除するCHAIN\_APPROX\_SIMPLEを用いる。
例えば、矩形であれば、各辺にある全ての点の座標を保存する必要はなく、4つの頂点の座標を保存することで、矩形の輪郭を表現できるため、それ以外の座標情報を削除する\cite{輪郭検出}。
本研究では、矩形領域座標取得処理(\ref{subsec:rect_coords_obtainment_processing}節で後述)で矩形の輪郭を検出するために用いる。

\paragraph{HoughLinesP関数}
HoughLinesP関数は、ハフ変換によって画像内にある直線を検出する関数である\cite{ハフ変換}。
ハフ変換は、二値画像中の直線や円を検出する手法の1つであり、画像空間から$\rho$-$\theta$空間に座標系を変換することで、直線や円を検出する手法である。
直線を検出する場合は、極座標の二次元平面に変換する。
直線上のある点の座標を$(x, y)$とすると、$\rho$は、座標$(x, y)$を通る直線に対して、原点から垂線を下ろしたときの長さ、$\theta$は、座標$(x, y)$を通る直線に対して、原点から垂線を下ろしたときに、X軸となす角度と表すことができる。
よって、以下の式が成り立つ。
\begin{equation}\label{eq:hough}
	\rho = x\cos\theta + y\sin\theta
\end{equation}
座標$(x, y)$を通る直線は無数に存在するため、式\ref{eq:hough}を満たす$(\rho, \theta)$も無数に存在する。
縦軸を$\rho$、横軸を$\theta$として、それらの$(\rho, \theta)$を、$\rho$-$\theta$空間に射影すると、曲線を図示できる。
この座標系の変換を、直線上の他にある$(x, y)$以外の座標に対して行ったとき、$\rho$-$\theta$空間に交点が存在する。
この操作を全画素に対して行い、$\rho$-$\theta$空間で多くの線が重なっている点$(\rho, \theta)$の中から、直線が存在する可能性が高い点$(\rho, \theta)$を探し、直線を検出する。
HoughLinesP関数を用いる際は、引数を以下の順で渡す\cite{HoughLinesP関数の引数}。

\begin{enumerate}
	\item 直線を検出する二値画像のパス
	\item 式\ref{eq:hough}における、$\rho$の値
	\item 式\ref{eq:hough}における、$\theta$の値
	\item 直線とみなす集合した点の数の閾値
	\item 直線とみなす最小の直線の長さ
	\item 同一直線とみなす2つの点の間隔の広さ
\end{enumerate}

これらを引数として渡すことによって、直線の両端点の2つのxy座標を出力する。
本研究では、下線部領域座標取得処理(\ref{subsec:underline_coords_obtainment_processing}節で後述)で直線を検出するために用いる。

\paragraph{drawContours関数}
drawContours関数は、輪郭を画像に描画する関数である。
drawContours関数を用いる際は、引数を以下の順で渡す\cite{輪郭描画}。
\begin{enumerate}
	\item 輪郭を描画する画像のパス
	\item 描画する輪郭のリスト
	\item 第二引数のうち、描画する輪郭のインデックス($-1$を指定することで、全輪郭を描画する)
	\item 輪郭を描画する線のRGBカラーを示すタプル
	\item 輪郭を描画する線の太さ
\end{enumerate}
本研究では、文字情報取得用画像処理(\ref{subsec:image_processing_for_char_recognition}節で後述)で黒色の矩形と直線を描画するためと、領域強調画像出力処理(\ref{subsec:area_highlighted_image_output_processing}節で後述)で矩形領域と下線部領域を描画するために用いる。

\paragraph{putText関数}
putText関数は、文字を画像に描画する関数である。
本研究では、領域強調画像出力処理(\ref{subsec:area_highlighted_image_output_processing}節で後述)で領域とラベルを描画するために用いる。

\section{光学文字認識}\label{sec:Optical-Charactor-Recognition}
光学文字認識(Optical Charactor Recognition)とは、文字を含む画像から文字を識別し、文字コードに変換する処理である\cite{光学文字認識}。
本研究では、文字情報取得処理(\ref{subsec:char_information_obtainment_processing}節で後述)で、文字と、文字を囲むバウンディングボックスの各頂点のxy座標を取得するために用いる。
また、本研究では、光学文字認識ソフトウェア\cite{光学文字認識ソフトウェア}の1つであるTesseract-OCR\cite{Tesseract-OCR}を、PythonのOCR用のラッパーライブラリであるPyOCR\cite{PyOCR}から用いる。
PyOCRを用いる際に、文字を認識する処理にbuilderという変数を引数として指定できる。

本研究では、変数builder、行単位で、文字と、文字を囲むバウンディングボックスの各頂点のxy座標を同時に取得するLineBoxBuilderを指定する。

\section{DeblurGANv2}\label{sec:DeblurGANv2}
DeblurGANv2は、敵対的生成ネットワーク(Generative Adversarial Network)をブレ除去に適用したツールである\cite{DeblurGANv2}。
スマートフォンで帳票画像を撮影する際に発生する画像内のブレを除去し、領域座標と文字認識の精度を高めることを目的として適用する。
また、先行研究において、スマートフォンのカメラで撮影した画像に対して、複数の画像処理と共にDeblurGANv2を適用することによって、ブレ除去によって画像品質が向上し、Tesseract-OCRを用いた光学文字認識の精度が向上することが示されている\cite{DeblurGANv2の先行研究}。

本研究では、領域取得部(\ref{sec:area_coords_obtainment_part}節で後述)と文字情報取得部(\ref{sec:OCR_part}節で後述)で行う画像処理の一部に用いる。

\section{Fugashi}\label{sec:Fugashi}
Fugashiは、形態素解析ソフトウェアであるMecab\cite{Mecab}をPythonで使用する際のラッパーライブラリである\cite{Fugashi}。

本研究では、除外推測処理(\ref{subsec:exclusion_judgement_processing}節で後述)で属性推測処理に不要な文字を、文字を構成する形態素の品詞を参照することによって、出力の対象外とするために用いる。
また、本研究でFugashiの解析に用いる辞書として、UniDic\cite{UniDic}を利用する。
よって、本論文で記述する品詞体系は、UniDic品詞体系とする。
UniDic品詞体系では、左からカンマ区切りで、大分類、中分類、小分類、細分類の順で品詞を列挙する\cite{UniDic品詞体系}。

\section{Youri}\label{sec:Youri}
Youriは、2023年10月にrinna株式会社\cite{rinna}がオープンソースで公開した、Llama2\cite{Llama2}に対し、日本語の学習データで継続事前学習を行うことによって、日本語のテキスト生成能力を高めた大規模言語モデルである\cite{Youri}。

使用する大規模言語モデルをYouriに選定した理由を、以下に示す。

\begin{itemize}
    \item ローカル環境で推論が可能である\\
        属性推測処理では、帳票画像の文字をプロンプトとして入力する。
        APIを介してプロンプトを外部に送信する場合、帳票画像内に記載された内容が流出する可能性がある。
        帳票には、機密情報や個人情報を含む可能性があるため、ローカル環境で処理を完結する。
    \item 日本語の推論に特化している\\
        Youriは、rinna社が公開した、Llama2に対して日本語の学習データで継続事前学習を行った、大規模言語モデルである。
        日本語の推論に特化しており、推測する属性の精度が高い。
    \item 軽量であり、高速に属性を推測できる\\
        YouriはAPIを介さない他の言語モデルと比較して、高速である。
        属性推測処理では、取得した文字の回数だけYouriにプロンプトを入力し、返答を待つ必要がある。
        属性の推測にかかる時間が短いモデルを選定することで、属性の推測にかかる時間を短縮する。
\end{itemize}

本研究では、属性推測処理(\ref{subsec:att_prediction_processing}節で後述)で取得文字の属性を推測するために用いる。

\section{IoU}\label{sec:IoU}
IoUは、物体検出において、2つの領域の重なり度合いを表す指標であり、1.0で完全一致、0.0で重なりがないことを示す。

IoUを算出する式を、以下に示す。
なお、一般に、IoUは0.5を閾値として、閾値以上である場合は2つの領域が致しているとみなす\cite{IoU閾値}。

\begin{equation}
    \rm{IoU} = \frac{2つの領域の積集合の面積}{2つの領域の和集合の面積}
\end{equation}